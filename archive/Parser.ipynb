{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "import fitz\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(raw_data_path):\n",
    "    for filename in filenames: \n",
    "        files.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = []\n",
    "for file in files:\n",
    "    if \"pdf\" in file:\n",
    "        pdfs.append({\"pdf\": PdfReader(file),\"path\": file})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pdf['pdf'].pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = []\n",
    "#for pdf in pdfs:\n",
    "pdf = pdfs[0]\n",
    "print(\"The case document path: \", pdf['path'])\n",
    "print(\"The # of page in this document:\", len(pdf['pdf'].pages))\n",
    "for index, page in enumerate(pdf['pdf'].pages):\n",
    "#page = pdf['pdf'].pages[5]\n",
    "    text = page.extract_text()\n",
    "    #splitted_text = re.findall('\\n\\d+\\.  ', text)\n",
    "    p = re.compile(\"\\n\\d+\\.  \")\n",
    "    for m in p.finditer(text):\n",
    "        l = [int(s) for s in re.findall(\"\\d+\", m.group())]\n",
    "        if l is not None:\n",
    "            sections.append({'number': l[0], 'start': m.start(), 'page_num': index, 'text': text})\n",
    "\n",
    "    #sections+=splitted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### ONLY FOR TEST PURPOSES ####\n",
    "# sections = []\n",
    "# page_num = 5\n",
    "# page = pdf['pdf'].pages[page_num]\n",
    "# text = page.extract_text()\n",
    "# p = re.compile(\"\\n\\d+\\.  \")\n",
    "# start = 0\n",
    "# for m in p.finditer(text):\n",
    "#     end = m.start()\n",
    "#     print(m.group())\n",
    "#     l = [int(s) for s in re.findall(\"\\d+\", m.group())]\n",
    "#     if l is not None:\n",
    "#         sections.append({'number': l[0], 'start': m.start(), 'page_num': page_num})\n",
    "# #splitted_text = re.findall('\\n\\d+\\.  ', text)\n",
    "# #sections+=splitted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['page_num'] >= 4 ]\n",
    "df['text'][55]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['end'] = df['start'].shift(-1)\n",
    "df['end'] = df.groupby('page_num')['start'].shift(-1)\n",
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = []\n",
    "real_index = 1\n",
    "for index, row in df.iterrows():\n",
    "    if real_index == 1 and real_index < row['number']:\n",
    "        continue\n",
    "    elif real_index > row['number']:\n",
    "        continue\n",
    "    else:\n",
    "        text = row['text']\n",
    "        real_data.append({ 'number': real_index, 'page_num': row['page_num'], 'text': text[int(row['start']):int(row['end'])], 'start': row['start'], 'end': row['end'] })\n",
    "        real_index += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation centric regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '/Annots'\n",
    "ank = '/A'\n",
    "uri = '/URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperlinks_in_a_page(doc, page_number, key, uri, ank):\n",
    "    urls = []\n",
    "    \n",
    "    # Access the specific page using list-like indexing\n",
    "    page = doc.pages[page_number]\n",
    "    \n",
    "    # Extract the page's object dictionary\n",
    "    pageObject = page.get_object()\n",
    "    \n",
    "    # Check if the key exists in the page's object dictionary\n",
    "    if key in pageObject:\n",
    "        ann = pageObject[key]\n",
    "        \n",
    "        # Iterate over the annotations\n",
    "        for a in ann:\n",
    "            u = a.get_object()\n",
    "            \n",
    "            # Check if the URI is in the annotation dictionary\n",
    "            if uri in u and ank in u[uri]:\n",
    "                urls.append(u[uri][ank])\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pdfs[0]['pdf']\n",
    "page = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_hyperlinks_in_a_page(doc, page, key, uri, ank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0]['/A']['/URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0]['/Rect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"raw_data/Guide_Art_1_ENG.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = page.get_links()[2]['from']\n",
    "text = page.get_textbox(rect)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSliced = doc.getPage(page)\n",
    "pageObject = pageSliced.getObject()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObject.getContents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if key in pageObject.keys():\n",
    "    ann = pageObject[key]\n",
    "    for a in ann:\n",
    "        u = a.getObject()\n",
    "        if uri in u[ank].keys():\n",
    "            print(u['/StructParent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Box Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
    "                            styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
    "                                                  'color': s['color']}\n",
    "                        else:\n",
    "                            identifier = \"{0}\".format(s['size'])\n",
    "                            styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
    "\n",
    "                        font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
    "\n",
    "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if len(font_counts) < 1:\n",
    "        raise ValueError(\"Zero discriminating fonts found!\")\n",
    "\n",
    "    return font_counts, styles\n",
    "\n",
    "\n",
    "def font_tags(font_counts, styles):\n",
    "    \"\"\"Returns dictionary with font sizes as keys and tags as value.\n",
    "    :param font_counts: (font_size, count) for all fonts occuring in document\n",
    "    :type font_counts: list\n",
    "    :param styles: all styles found in the document\n",
    "    :type styles: dict\n",
    "    :rtype: dict\n",
    "    :return: all element tags based on font-sizes\n",
    "    \"\"\"\n",
    "    p_style = styles[font_counts[0][0]]  # get style for most used font by count (paragraph)\n",
    "    p_size = p_style['size']  # get the paragraph's size\n",
    "\n",
    "    # sorting the font sizes high to low, so that we can append the right integer to each tag\n",
    "    font_sizes = []\n",
    "    for (font_size, count) in font_counts:\n",
    "        font_sizes.append(float(font_size))\n",
    "    font_sizes.sort(reverse=True)\n",
    "\n",
    "    # aggregating the tags for each font size\n",
    "    idx = 0\n",
    "    size_tag = {}\n",
    "    for size in font_sizes:\n",
    "        idx += 1\n",
    "        if size == p_size:\n",
    "            idx = 0\n",
    "            size_tag[size] = '<p>'\n",
    "        if size > p_size:\n",
    "            size_tag[size] = '<h{0}>'.format(idx)\n",
    "        elif size < p_size:\n",
    "            size_tag[size] = '<s{0}>'.format(idx)\n",
    "\n",
    "    return size_tag\n",
    "\n",
    "\n",
    "def headers_para(doc, size_tag):\n",
    "    \"\"\"Scrapes headers & paragraphs from PDF and return texts with element tags.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param size_tag: textual element tags for each size\n",
    "    :type size_tag: dict\n",
    "    :rtype: list\n",
    "    :return: texts with pre-prended element tags\n",
    "    \"\"\"\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                block_string = size_tag[s['size']] + s['text']\n",
    "                            else:\n",
    "                                if s['size'] == previous_s['size']:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += \" \" + s['text']\n",
    "\n",
    "                                else:\n",
    "                                    header_para.append(block_string)\n",
    "                                    block_string = size_tag[s['size']] + s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "                    block_string += \"|\"\n",
    "\n",
    "                header_para.append(block_string)\n",
    "\n",
    "    return header_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(pdfs[0]['path'])\n",
    "font_counts, styles = fonts(doc, granularity=False)\n",
    "\n",
    "size_tag = font_tags(font_counts, styles)\n",
    "\n",
    "elements = headers_para(doc, size_tag)\n",
    "\n",
    "with open(\"doc.json\", 'w') as json_out:\n",
    "    json.dump(elements, json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_sample_number = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedPDF   = parser.from_file(pdfs[pdf_sample_number]['path'])\n",
    "content     = parsedPDF['content']\n",
    "metadata    = parsedPDF['metadata']\n",
    "print(pdfs[pdf_sample_number]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Hierarchy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_roman(num):\n",
    " \n",
    "    # Storing roman values of digits from 0-9\n",
    "    # when placed at different places\n",
    "    m = [\"\", \"M\", \"MM\", \"MMM\"]\n",
    "    c = [\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\",\n",
    "         \"DC\", \"DCC\", \"DCCC\", \"CM \"]\n",
    "    x = [\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\",\n",
    "         \"LX\", \"LXX\", \"LXXX\", \"XC\"]\n",
    "    i = [\"\", \"I\", \"II\", \"III\", \"IV\", \"V\",\n",
    "         \"VI\", \"VII\", \"VIII\", \"IX\"]\n",
    " \n",
    "    # Converting to roman\n",
    "    thousands = m[num // 1000]\n",
    "    hundreds = c[(num % 1000) // 100]\n",
    "    tens = x[(num % 100) // 10]\n",
    "    ones = i[num % 10]\n",
    " \n",
    "    ans = (thousands + hundreds +\n",
    "           tens + ones)\n",
    " \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_num_upper_list = {}\n",
    "roman_num_lower_list = {}\n",
    "for num in range(1,20):\n",
    "    roman_num_upper = int_to_roman(num)+\".\"\n",
    "    roman_num_lower = str.lower(roman_num_upper) \n",
    "    roman_num_upper_list[roman_num_upper] = num\n",
    "    roman_num_lower_list[roman_num_lower] = num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Header Hierarchy Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_of_content_pattern = '.+\\.   [^.]+[\\.]{5,1000} \\d+'\n",
    "#table_of_content_start_pattern = '.+\\.   |\\n{1,2} [A-Z]'\n",
    "#table_of_content_end_pattern = '[\\.]{5,1000}'\n",
    "#list_of_cited_cases_pattern =  'List[^.]+[. ]*\\d+'\n",
    "\n",
    "#table_of_content_start_pattern = '.{1,4}\\.   '\n",
    "#table_of_content_start_pattern = '\\n[IV]{1,3}\\. {1,3}|\\n[a-z]{1,3}\\. {1,3}|\\n[A-Z]{1,3}\\. {1,3}|\\n[0-9]{1,3}\\. {1,3}'\n",
    "table_of_content_end_pattern = '[.]{3,1000} *\\d+| [.]{1,1000} *\\d+'\n",
    "\n",
    "#table_of_content_end_pattern = '[.]{0,1000} \\d+ \\n'\n",
    "table_of_content_start_pattern = '\\n.{1,3}\\. {1,3}'\n",
    "#table_of_content_end_pattern = '[.]{1,1000}'\n",
    "list_of_cited_cases_pattern =  'List[^.]+[. ]*\\d+'\n",
    "\n",
    "#table_of_content = re.findall(table_of_content_end_pattern, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pattern = re.compile(table_of_content_start_pattern)\n",
    "end_pattern = re.compile(table_of_content_end_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = re.compile(list_of_cited_cases_pattern).search(content).span()[0]\n",
    "start_of_the_guide = 0\n",
    "for e in end_pattern.finditer(content):\n",
    "    if e.start() > start_list:\n",
    "        text = content[start_list:e.start()]\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        list_of_cases_text = text\n",
    "        start_of_the_guide = e.end()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[start_list:re.compile(list_of_cited_cases_pattern).search(content).span()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_content = []\n",
    "last_confirmed_end = 0\n",
    "for s in start_pattern.finditer(content[:start_of_the_guide]):\n",
    "    #print(content[s.start():s.end()])\n",
    "    for e in  end_pattern.finditer(content):\n",
    "        if e.start() > s.start():\n",
    "            text = content[s.start():e.start()]\n",
    "            text = text.replace(\"\\n\", \"\")\n",
    "            table_of_content.append(text)\n",
    "            last_confirmed_end = e.end()-1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_content.append(list_of_cases_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content[:start_of_the_guide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content[:e.end()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_content = content[start_of_the_guide:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subheader_pattern = '[A-Z]\\. *.+'\n",
    "section_pattern = '[0-9]+\\. *.+'\n",
    "subsection_pattern = '[a-z]+\\. *.+'\n",
    "#subheader_pattern = '[A-Z]\\. *.+'\n",
    "#section_pattern = '[0-9]+\\. *.+'\n",
    "#subsection_pattern = '[a-z]+\\. *.+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(subheader_pattern, 'A.   The concept of “finding of guilt” ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a different subheader pattern\n",
    "#subheader_pattern = '.+[\\.]{1,1000}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_case = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "header_index = -1\n",
    "subheader_index = -1\n",
    "section_index = -1\n",
    "for element in (table_of_content[:-1]):\n",
    "    print(repr(element), header_index, subheader_index, section_index)\n",
    "    element = element.rstrip(\" \")\n",
    "    # finding whether it's a header\n",
    "    for roman_upper in roman_num_upper_list.keys():\n",
    "        if roman_upper in element and roman_num_upper_list[roman_upper] > (header_index): # this element is a header\n",
    "            header.append({\"text\": element.rstrip(\".\").rstrip(\" \"), \"subheader\": []})\n",
    "            #print(element.rstrip(\".\").rstrip(\" \"))\n",
    "            header_index += 1\n",
    "            subheader_index = -1\n",
    "            break\n",
    "    else:\n",
    "        # finding whether it's a subheader or section or subsection\n",
    "        subheader_matcher = re.compile(subheader_pattern)\n",
    "        section_matcher = re.compile(section_pattern)\n",
    "        subsection_matcher = re.compile(subsection_pattern)\n",
    "        if subheader_matcher.match(element): # this element is a subheader\n",
    "            header[header_index]['subheader'].append({\"text\": element.rstrip(\".\").rstrip(\" \"), \"section\": []})\n",
    "            subheader_index += 1\n",
    "            section_index = -1\n",
    "        elif section_matcher.match(element): # this element is a section\n",
    "            if special_case and subheader_index == -1:\n",
    "                header[header_index]['subheader'].append({\"text\": \"\", \"section\": []})\n",
    "                subheader_index += 1\n",
    "                section_index = -1\n",
    "            header[header_index]['subheader'][subheader_index]['section'].append({\"text\": element.rstrip(\".\").rstrip(\" \"), \"subsection\": []})\n",
    "            section_index += 1\n",
    "        else: # this element is a subsection\n",
    "            if special_case and section_index == -1:\n",
    "                header[header_index]['subheader'][subheader_index]['section'].append({\"text\": \"\", \"subsection\": []})\n",
    "                section_index += 1\n",
    "            header[header_index]['subheader'][subheader_index]['section'][section_index]['subsection'].append({\"text\": element.rstrip(\".\").rstrip(\" \")})\n",
    "    \n",
    "# special case list of cases header\n",
    "header.append({\"text\": table_of_content[-1].rstrip(\".\").rstrip(\" \"), \"subheader\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting content after the table of content section. Now we have hierarchy for the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_pattern = r'http[s]?:\\/\\/hudoc.echr.coe.int\\/[a-z]+\\?i\\=\\d+\\-\\d+'\n",
    "website_pattern = r'([^ :]*):\\/\\/(?:([^:]*):([^@]*)@|)([^/:]{1,}):?(\\d*)?(\\/[^? ]*)\\??((?:[^=&# ]*=?[^&# ]*&?)*)#?([^ ]*)?'\n",
    "footer_pattern = r\" *Guide on Article \\d+ of the Convention \\- [A-Za-z ]+ European Court of Human Rights \\d+\\/\\d+ Last update: \\d+.\\d+.\\d+ *\"\n",
    "citation_pattern = \"[A-Z]+[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+[GCIdecmeritsrevision\\[\\]().\\d\\- ]*[S,\\d ]*[\\-\\d ]*[and]{0,3}[\\-\\d ]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text, website_pattern, footer_pattern):\n",
    "    sentences = re.sub(\"\\n\", \" \\n \", text)\n",
    "    sentences = unidecode.unidecode(sentences)\n",
    "    sentences = re.sub(website_pattern, '', sentences)\n",
    "    sentences = re.sub(\" \\n \", \"\", sentences)\n",
    "    sentences = re.sub(footer_pattern, ' ', sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_pattern(text):\n",
    "    #print(text)\n",
    "    #text = re.sub(\"-\", \" - \", text)\n",
    "    lst = re.split(\" \", text)\n",
    "    r = [x for x in lst if len(x) > 0]\n",
    "    pat = \"\"\n",
    "    for i, e in enumerate(r):\n",
    "        current_pat = e\n",
    "        shifter = 0\n",
    "        for p in re.compile(\"[()\\[\\]]\").finditer(e):\n",
    "            index = p.start() + shifter\n",
    "            current_pat = current_pat[:index] + '\\\\' +current_pat[index:]\n",
    "            #print(repr(current_pat))\n",
    "            shifter +=1 \n",
    "        if i < len(r) - 1:\n",
    "            pat += current_pat + \" *\\n*\"\n",
    "            #pat += current_pat + \"[\\d{0,2}\\n ]*\"\n",
    "        else:\n",
    "            pat += current_pat\n",
    "    #print(repr(pat))\n",
    "    return pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in re.compile(get_the_pattern(header[2][\"text\"])).finditer(clear_content):\n",
    "    print(e.group(), e.start(), e.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = clear_content[41308:44158]\n",
    "#tmp\n",
    "#tmp_pat = get_the_pattern('4. Mental illness/measure of protection')\n",
    "#tmp = \"licences). \\n\\n4.  Proportionality and related issues (fair balance, compensation, margin of \\nappreciation) \\n\\n142.  In order to be compatible with the general rule set forth in the first sentence of the first \\nparagraph of Article 1 of Protocol No. 1, an interference with the right to the peaceful enjoyment of \\n“possessions”, apart from being prescribed by law and in the public interest, must strike a “fair \\nbalance” between the demands of the general interest of the community and the r\"\n",
    "#print(re.findall(tmp_pat,tmp))\n",
    "#tmp_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.findall(get_the_pattern(tmp_pat), tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for head in header:\n",
    "    current_pattern = get_the_pattern(head['text'])\n",
    "    start = re.compile(current_pattern).search(clear_content).span()[0]\n",
    "    end = re.compile(current_pattern).search(clear_content).span()[1]\n",
    "    #print(re.findall(current_pattern, clear_content), \"pattern:\", repr(current_pattern))\n",
    "    titles.append({\n",
    "        \"type\": \"header\", \n",
    "        \"start\": start, \n",
    "        \"end\": end,\n",
    "        \"header\": clear_content[start:end],\n",
    "        \"subheader\": None, \n",
    "        \"section\": None,\n",
    "        'subsection': None\n",
    "        })\n",
    "    for subheader in head['subheader']:\n",
    "        current_pattern = get_the_pattern(subheader['text'])\n",
    "        #print(\"\\t\", re.findall(current_pattern, clear_content), \"pattern:\",  repr(current_pattern))\n",
    "        start = re.compile(current_pattern).search(clear_content).span()[0]\n",
    "        end = re.compile(current_pattern).search(clear_content).span()[1]\n",
    "        titles.append({\n",
    "            \"type\": \"subheader\", \n",
    "            \"start\": start,\n",
    "            \"end\": end, \n",
    "            \"header\": head['text'], \n",
    "            \"subheader\": clear_content[start:end],\n",
    "            \"section\": None,\n",
    "            'subsection': None\n",
    "            })\n",
    "        for section in subheader['section']:\n",
    "            current_pattern = get_the_pattern(section['text'])\n",
    "            #print(\"\\t\\t\", re.findall(current_pattern, clear_content), \"pattern:\", repr(current_pattern))\n",
    "            start = re.compile(current_pattern).search(clear_content).span()[0]\n",
    "            end = re.compile(current_pattern).search(clear_content).span()[1]\n",
    "            titles.append({\n",
    "                \"type\": \"section\", \n",
    "                \"start\": start, \n",
    "                \"end\": end, \n",
    "                \"header\": head['text'], \n",
    "                \"subheader\": subheader['text'],\n",
    "                \"section\": clear_content[start:end],\n",
    "                \"subsection\": None\n",
    "                })\n",
    "            for subsection in section['subsection']:\n",
    "                current_pattern = get_the_pattern(subsection['text'])\n",
    "                #print(\"\\t\\t\\t\", re.findall(current_pattern, clear_content), \"pattern:\", repr(current_pattern))\n",
    "                start = re.compile(current_pattern).search(clear_content).span()[0]\n",
    "                end = re.compile(current_pattern).search(clear_content).span()[1]\n",
    "                #print(re.compile(current_pattern).findall(content), start, end)\n",
    "                titles.append({\n",
    "                    \"type\": \"subsection\", \n",
    "                    \"start\": start, \n",
    "                    \"end\": end, \n",
    "                    \"header\": head['text'], \n",
    "                    \"subheader\": subheader['text'], \n",
    "                    \"section\": section['text'],\n",
    "                    \"subsection\": clear_content[start:end], \n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchy now is located in the text itself, now we will get the inner sections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions and Regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_arr = [\"Guide on Article 1 of the Convention – Obligation to respect human rights – Concepts of “jurisdiction” and imputability\",\n",
    "\"Guide on Article 1 of Protocol No. 1 – Protection of property\",\n",
    "\"Guide on Article 1 of Protocol No. 7 to the Convention – Procedural safeguards on expulsion\"\n",
    "\"Guide on Article 2 of the Convention – Right to life\",\n",
    "\"Guide on Article 2 of Protocol No. 1 – Right to education\",\n",
    "\"Guide on Article 3 of the Convention – Prohibition of torture\",\n",
    "\"Guide on Article 2 of Protocol No. 4 to the Convention – Freedom of movement\",\n",
    "\"Guide on Article 3 of Protocol No. 1 – Right to free elections\",\n",
    "\"Guide on Article 3 of Protocol N° 4 to the Convention – Prohibition of expulsion of nationals\"\n",
    ",\"Guide on Article 4 of the Convention – Prohibition of slavery and forced labour\"\n",
    ",\"Guide on Article 4 of Protocol No. 4 – Prohibition of collective expulsion of aliens\"\n",
    ",\"Guide on Article 4 of Protocol No. 7 – Right not to be tried or punished twice\"\n",
    ",\"Guide on Article 5 of the Convention – Right to liberty and security\"\n",
    ",\"Guide on Article 6 of the Convention – Right to a fair trial (criminal limb)\"\n",
    ",\"Guide on Article 6 of the Convention – Right to a fair trial (civil limb)\"\n",
    ",\"Guide on Article 7 of the Convention – No punishment without law\"\n",
    ",\"Guide on Article 8 of the Convention – Right to respect for private and family life\"\n",
    ",\"Guide on Article 9 of the Convention – Freedom of thought, conscience and religion\"\n",
    ",\"Guide to Article 10 of the Convention – Freedom of expression\"\n",
    ",\"Guide on Article 11 of the Convention – Freedom of assembly and association\"\n",
    ",\"Guide on Article 12 of the Convention – Right to marry\"\n",
    ",\"Guide on Article 13 of the Convention – Right to an effective remedy\"\n",
    ",\"Guide on Article 14 of the Convention (prohibition of discrimination) and on Article 1 of Protocol No. 12 (general prohibition of discrimination)\"\n",
    ",\"Guide on Article 15 of the Convention – Derogation in time of emergency\"\n",
    ",\"Guide on Article 17 of the Convention – Prohibition of abuse of rights\"\n",
    ",\"Guide on Article 18 of the Convention – Limitation on use of restrictions on rights\"\n",
    ",\"Guide on Article 46 of the Convention – Binding force and execution of judgments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_pattern = r'http[s]?:\\/\\/hudoc.echr.coe.int\\/[a-z]+\\?i\\=\\d+\\-\\d+'\n",
    "website_pattern = r'([^ :]*):\\/\\/(?:([^:]*):([^@]*)@|)([^/:]{1,}):?(\\d*)?(\\/[^? ]*)\\??((?:[^=&# ]*=?[^&# ]*&?)*)#?([^ ]*)?'\n",
    "footer_pattern = r\" *Guide [ton]{2} Article \\d+ of [A-Za-z\\(\\)\\d\\.\\\",\\- ]*European *Court *of *Human *Rights *\\d+\\/\\d+ *Last *update: *\\d+.\\d+.\\d+ *\"\n",
    "citation_pattern = \"[A-Z]+[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+[GCIdecmeritsrevision\\[\\]().\\d\\- ]*[S,\\d ]*[\\-\\d ]*[and]{0,3}[\\-\\d ]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(footer_pattern).findall( 'Guide on Article 1 of Protocol No. 1 - Protection of property European Court of Human Rights 89/98 Last update: 31.08.2022 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic = \"[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+\"\n",
    "#gc = \"[\\[GC\\]]*\"\n",
    "#dec = \"[\\(dec\\.\\)]*\"\n",
    "#year = \"[ \\d\\d\\d\\d]*\"\n",
    "#par = \"[ S{2,4}]*\"\n",
    "#revision = \"[\\(revision\\)]*\"\n",
    "#no = \"[\\(no\\. \\d*\\)]*\"\n",
    "#par_interval = \"[ \\d+\\-*\\d*]*\"\n",
    "#alternative_par_interval = \"[and \\d+\\-*\\d*]*\"\n",
    "#suffix_pattern = \"where.*|which.*|which.*|in which.*\"\n",
    "#semi_column = \"[;),]?\"\n",
    "#citation_pattern = generic + gc + dec + revision + no + \",*\" + year + par + par_interval + alternative_par_interval + semi_column\n",
    "#cleaner = \"[ \\.,:;()]*\"\n",
    "citation_pattern = \"[A-Z]+[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+[GCIdecmeritsrevision\\[\\]().\\d\\- ]*[S,\\d ]*[\\-\\d ]*[and]{0,3}[\\-\\d ]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content[5666:6452]\n",
    "range(len(titles) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffix_checker(text):\n",
    "    suffix_pattern_list = (\"where\", \"which\", \"in which\")\n",
    "    return text.lstrip(\"[ \\.,:;()]*\").startswith(suffix_pattern_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = clear_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_num = 1\n",
    "result_dic = []\n",
    "first = False\n",
    "#citation_str  = []\n",
    "for index in range(len(titles) - 1):\n",
    "\n",
    "    ## Getting the raw text between the titles\n",
    "    if index < len(titles) - 1:\n",
    "        #print(content[titles[index]['end']:titles[index+1]['start']])\n",
    "        raw_text = content[titles[index]['end']:titles[index+1]['start']]\n",
    "    #    raw_text = content[titles[index]['end']:]\n",
    "        \n",
    "    article_subs = re.split(\"\\n\\d+\\. *\", raw_text)[1:]\n",
    "    nums = re.findall(\"\\n\\d+\\. *\", raw_text)\n",
    "\n",
    "    for num, art in zip(nums, article_subs):\n",
    "        if first:\n",
    "            rule_num = int(re.findall(\"\\d+\", num)[0])\n",
    "            first = False\n",
    "        #print(num, \":\", art)\n",
    "            #print(rule_num, ':', art)\n",
    "        if rule_num == int(re.findall(\"\\d+\", num)[0]) or (False and int(re.findall(\"\\d+\", num)[0]) > rule_num):\n",
    "            rule_num = int(re.findall(\"\\d+\", num)[0])\n",
    "            sentences = re.sub(\"\\n\", \" \\n \", art)\n",
    "            sentences = unidecode.unidecode(sentences)\n",
    "            sentences = re.sub(website_pattern, '', sentences)\n",
    "            sentences = re.sub(\" \\n \", \"\", sentences)\n",
    "            sentences = re.sub(footer_pattern, ' ', sentences)\n",
    "            citations = re.findall(citation_pattern, sentences) \n",
    "            rules = re.split(citation_pattern, sentences)\n",
    "            rule_index = 0\n",
    "            for citation_index, citation in enumerate(citations):\n",
    "                citation_type = \"single\"\n",
    "                suffix = None\n",
    "                if len(rules[citation_index]) > 5 and not suffix_checker(rules[citation_index]): # this is not a suffix as well \n",
    "                    rule = rules[citation_index]\n",
    "                    #citation_str.append({\"rule_num\": rule_num,\"text\":rules[citation_index][-1]})\n",
    "                    if len(rules) > citation_index + 1 and suffix_checker(rules[citation_index+1]): # there is a suffix after that sentence\n",
    "                        suffix = rules[citation_index+1]\n",
    "                    rule_index = citation_index\n",
    "                else:\n",
    "                    # multicitation or in sentence citation\n",
    "                    if len(rules[citation_index].strip()) == 0 and citation_index == 0: # in sentence citation, just direct to the next sentence\n",
    "                        rule_index += 1\n",
    "                        rule = rules[rule_index]\n",
    "                        citation_type = \"in_sentence\"\n",
    "                    else:\n",
    "                        citation_type = \"multi\"\n",
    "                        result_dic[-1]['citation_type'] = citation_type\n",
    "                        #if len(rules[citation_index+1]) >  0:\n",
    "                        #    citation_str.append({\"rule_num\": rule_num,\"text\":rules[citation_index+1][:max(1, len(rules[citation_index+1]))]})\n",
    "                        if len(rules) > citation_index + 1 and suffix_checker(rules[citation_index+1]):\n",
    "                            suffix = rules[citation_index+1]\n",
    "                        rule = rules[rule_index] # multi citation, just keep the old sentence\n",
    "\n",
    "                result_dic.append({\n",
    "                        \"rule_num\": rule_num, \n",
    "                        \"sentence\": rule, \n",
    "                        \"citation\": citation,\n",
    "                        \"citation_type\": citation_type,\n",
    "                        \"suffix\": suffix,\n",
    "                        \"header\": titles[index]['header'], \n",
    "                        \"subheader\": titles[index]['subheader'],\n",
    "                        'section': titles[index]['section'],\n",
    "                        \"subsection\": titles[index]['subsection']\n",
    "                        })\n",
    "                #print(titles[index])\n",
    "                \n",
    "            rule_num += 1\n",
    "        else:\n",
    "            #print(\"not a rule\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(result_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['citation_type'] == \"in_sentence\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../example_output_new_regex.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding corresponding url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_citations_letter = []\n",
    "p = re.compile(\"—[A-Z]—\")\n",
    "index = 0\n",
    "for m in p.finditer(content):\n",
    "    url_citations_letter.append({ 'url_citation_letter': m.group(), 'start': m.start(), 'end': 0})\n",
    "    if index > 0:\n",
    "        url_citations_letter[index-1]['end'] = m.start()\n",
    "    index += 1    \n",
    "url_citations_letter[index-1]['end'] = len(content)\n",
    "#sections+=splitted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_pattern_url = r\" *Guide [ton]{2} Article \\d+ of [A-Za-z\\(\\)\\d\\.\\\",\\- ]*\\n*European *\\n*Court *\\n*of *\\n*Human *\\n*Rights *\\n*\\d+\\/\\d+ *\\n*Last *\\n*update: *\\n*\\d+.\\d+.\\d+ *\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(\"-[A-Z]-\").search(unidecode.unidecode(content)).span()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = re.findall(footer_pattern_url, unidecode.unidecode(content[436622:]))[0]\n",
    "nums = re.findall('\\d+\\/\\d+', tmp)[0]\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(pdfs[1]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc[int(re.split(\"/\", nums)[0]) - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = page.get_links()\n",
    "links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(int(re.split(\"/\", nums)[0]) - 2, len(doc)):\n",
    "    page  = doc[index]\n",
    "    links = page.get_links()\n",
    "    for link in links:\n",
    "        rect = link['from']\n",
    "        text = page.get_textbox(rect)\n",
    "        print(link['uri'], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_citations_text = [content[url_citation['start']:url_citation['end']] for url_citation in url_citations_letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(url_citations_text[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_citations_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_letter_text = []\n",
    "for every_letter in url_citations_text:\n",
    "    footer_pattern_url = r\" *Guide [ton]{2} Article \\d+ of [A-Za-z\\(\\)\\d\\.\\\",\\- ]*\\n*European *\\n*Court *\\n*of *\\n*Human *\\n*Rights *\\n*\\d+\\/\\d+ *\\n*Last *\\n*update: *\\n*\\d+.\\d+.\\d+ *\"\n",
    "    current_letter = every_letter[1]\n",
    "    sample_letter_text = unidecode.unidecode(every_letter)\n",
    "    sample_letter_text = re.sub(footer_pattern_url,\"\", sample_letter_text)\n",
    "    #print(re.findall(footer_pattern_url, sample_letter_text))\n",
    "    interval_of_citations = []\n",
    "    for letter in re.compile(\"\\n\"+current_letter).finditer(sample_letter_text):\n",
    "        interval_of_citations.append({\"start\": letter.start(),\"end\":0})\n",
    "    for index, interval in enumerate(interval_of_citations):\n",
    "        if index < len(interval_of_citations)-1:\n",
    "            interval_of_citations[index]['end'] = interval_of_citations[index+1]['start']\n",
    "        else:\n",
    "            interval_of_citations[index]['end'] = len(sample_letter_text) # we have to deal with that part because there could be many unnnecessary strings here!\n",
    "        #print(repr(sample_letter_text[interval_of_citations[index]['start']: interval_of_citations[index]['end']]))\n",
    "        current_citation = sample_letter_text[interval_of_citations[index]['start']: interval_of_citations[index]['end']]\n",
    "        parts = re.split(\"[ \\n]*v\\.[ \\n]*\", current_citation)\n",
    "        if len(parts) >= 2:\n",
    "            clear_citation = parts[0]+\" v. \"+re.match(\"[^,]+\",parts[1]).group()\n",
    "        else:\n",
    "            clear_citation = current_citation\n",
    "        clear_citation = re.sub(\"\\n\", \"\", clear_citation)\n",
    "        citation_letter_text.append(clear_citation)\n",
    "\n",
    "citation_url = []\n",
    "for every_letter in url_citations_text:\n",
    "    sample_letter = re.split(\"\\n\", every_letter)\n",
    "    for sample in sample_letter:\n",
    "        sample = unidecode.unidecode(sample)\n",
    "        if \"http\" in sample:\n",
    "            citation_url.append(sample)\n",
    "    \n",
    "    \n",
    "    #for sample in re.compile(\"\\n\"+current_letter+\"^(?!.*(v\\.))v\\.[^,]+\").finditer(sample_letter):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(citation_letter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(citation_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "[k for k,v in Counter(citation_url).items() if v>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation_url = []\n",
    "#citation_letter_text = []\n",
    "#for every_letter in url_citations_text:\n",
    "#    sample_letter = re.split(\"\\n\", every_letter)\n",
    "#    for sample in sample_letter:\n",
    "#        sample = unidecode.unidecode(sample)\n",
    "#        if \"v.\" in sample:\n",
    "#            citation_letter_text.append(sample)\n",
    "#        elif \"http\" in sample:\n",
    "#            citation_url.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_mapper = {}\n",
    "for index, citation_text in  reversed(list(enumerate(citation_letter_text))):\n",
    "    current_index = index+max(0, len(citation_url) - len(citation_letter_text))\n",
    "    citation_mapper[citation_text] = citation_url[current_index]\n",
    "citation_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing URL with mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['citation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['citation'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_url_mapper(text, citation_mapper):\n",
    "    max = 0\n",
    "    current_best_distance_key = \"\"\n",
    "    final_key = \"\"\n",
    "    for key in citation_mapper.keys():\n",
    "        current_distance = jellyfish.jaro_similarity(key, text)\n",
    "        if max < current_distance:\n",
    "            max = current_distance\n",
    "            current_best_distance_key = key\n",
    "        #    final_key = citation_mapper[key]\n",
    "        if key in text:\n",
    "            final_key = citation_mapper[key]\n",
    "    else:\n",
    "        final_key = citation_mapper[current_best_distance_key]\n",
    "    return final_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['citation_url'] = data.apply(lambda row: citation_url_mapper(row['citation'], citation_mapper=citation_mapper), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../citation_oriented_raw_data_new_regex.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Manipulation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing the Sentences, getting the rule type and getting the paragraph numbers from citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data['sentence'] = data.apply(lambda row: row['sentence'].strip(\"[ \\.,:;()]*\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripped_data.apply(lambda row: \"example\" if \"#\" in row['sentence'] else \"rule\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data['rule_type'] = stripped_data.apply(lambda row: \"example\" if \"#\" in row['sentence'] else \"rule\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripped_data.apply(lambda row: print(row['citation'],\":\",re.compile(citation_number_pattern).findall(row['citation'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation_par_nums = []\n",
    "#for index, row in stripped_data.iterrows():\n",
    "#    citation_par_nums.append({\"citation\": row['citation'], \"numbers\": re.compile(citation_number_pattern).findall(row['citation'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation_par_nums_df = pd.DataFrame(citation_par_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_par_nums(row_text):\n",
    "    citation_number_pattern = \"S{2,4}.*\"\n",
    "    single = \"\\d{1,4}\"\n",
    "    double = \"\\d{1,4}\\-\\d{1,4}\"\n",
    "    nums = []\n",
    "    for par_num_text in re.compile(citation_number_pattern).finditer(row_text):\n",
    "        num_text = par_num_text.group()\n",
    "        if \"and\" in num_text:\n",
    "            for element in re.split(\" *and *\", num_text):\n",
    "                if len(element) > 0:\n",
    "                    interval = re.findall(single, element)\n",
    "                    for num in range(int(interval[0]), int(interval[-1]) + 1):\n",
    "                        nums.append(num)\n",
    "        else:\n",
    "            interval = re.findall(single, num_text)\n",
    "            for num in range(int(interval[0]), int(interval[-1]) + 1):\n",
    "                nums.append(num)\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data['citation_par_nums'] = stripped_data.apply(lambda row: capture_par_nums(row['citation']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = stripped_data[['rule_num','citation', 'citation_par_nums']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data.to_csv(\"../stripped_data_new_regex.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data['rule_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data['citation_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data[stripped_data['citation_url'] == \"\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data[stripped_data['citation_par_nums'].str.len() <= 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with content string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Paragraphs tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = content[titles[6]['end']:titles[7]['start']]\n",
    "#test_text = \"\\n\\n205.  Thus, it has held that, in cases where negligence by a private individual resulted in the victim’s \\ndeath or serious injury, the States’ duty to take appropriate steps to safeguard the lives of those \\nwithin its jurisdiction includes an obligation to have in place an effective independent judicial system \\nsecuring the availability of legal means capable of establishing the facts, holding accountable those \\nat fault and providing appropriate redress to the victim (Fergec v. Croatia, § 32, which concerned the \\neffectiveness of proceedings concerning the explosion of a grenade in a pizza parlour; Ciechońska \\n\\nhttp://hudoc.echr.coe.int/eng?i=001-189781\\nhttp://hudoc.echr.coe.int/eng?i=001-189781\\nhttp://hudoc.echr.coe.int/eng?i=001-208279\\nhttp://hudoc.echr.coe.int/eng?i=001-207757\\nhttp://hudoc.echr.coe.int/eng?i=001-207757\\nhttp://hudoc.echr.coe.int/eng?i=001-207757\\nhttp://hudoc.echr.coe.int/eng?i=001-208279\\nhttp://hudoc.echr.coe.int/eng?i=001-120961\\nhttp://hudoc.echr.coe.int/eng?i=001-173467\\nhttp://hudoc.echr.coe.int/eng?i=001-105102\\n\\n\\nGuide on Article 2 of the Convention – Right to life \\n\\nEuropean Court of Human Rights 44/56 Last update: 31.08.2022 \\n\\nv. Poland, 2011, § 66, which concerned proceedings regarding the death of the applicant’s husband \\nafter being hit by a tree in a health resort; Anna Todorova v. Bulgaria, 2011, § 72, which concerned \\nproceedings regarding the death of the applicant’s son in a road traffic accident; Ilbeyi Kemaloğlu \\nand Meriye Kemaloğlu v. Turkey, § 38, which concerned the death of the applicant’s seven-year old \\nson who froze to death while trying to walk home in a blizzard; Kotelnikov v. Russia, §§ 99-101, \\nwhere the applicant was seriously injured in a traffic accident).\"\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = \"[A-Za-z.\\- ]*v\\.[A-Za-z\\[\\]\\(\\)\\-\\d\\.S{2,4} ]+\"\n",
    "gc = \"[\\[GC\\]]*\"\n",
    "dec = \"[\\(dec\\.\\)]*\"\n",
    "year = \"[ \\d\\d\\d\\d]*\"\n",
    "par = \"[ S{2,4}]*\"\n",
    "revision = \"[\\(revision\\)]*\"\n",
    "no = \"[\\(no\\. \\d*\\)]*\"\n",
    "par_interval = \"[ \\d+\\-*\\d*]*\"\n",
    "alternative_par_interval = \"[and \\d+\\-*\\d*]*\"\n",
    "suffix_pattern = \"where.*|which.*|which.*|in which.*\"\n",
    "semi_column = \"[;),]?\"\n",
    "citation_pattern = generic + gc + dec + revision + no + \",*\" + year + par + par_interval + alternative_par_interval + semi_column\n",
    "cleaner = \"[ \\.,:;()]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_pattern = \"[A-Z]+[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+[GCIdecmeritsrevision\\[\\]().\\d\\- ]*[S,\\d ]*[\\-\\d ]*[and]{0,3}[\\-\\d ]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_pattern = \"where.*|which.*|in which.*\"\n",
    "suffix_pattern_list = (\"where\", \"which\", \"in which\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_pattern = r'http[s]?:\\/\\/hudoc.echr.coe.int\\/[a-z]+\\?i\\=\\d+\\-\\d+'\n",
    "website_pattern = r'([^ :]*):\\/\\/(?:([^:]*):([^@]*)@|)([^/:]{1,}):?(\\d*)?(\\/[^? ]*)\\??((?:[^=&# ]*=?[^&# ]*&?)*)#?([^ ]*)?'\n",
    "footer_pattern = r\" *Guide on Article \\d+ of the Convention \\- [A-Za-z ]+ European Court of Human Rights \\d+\\/\\d+ Last update: \\d+.\\d+.\\d+ *\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_subs = re.split(\"\\n\\d+\\. \", test_text)[1:]\n",
    "nums = re.findall(\"\\n\\d+\\. \", test_text)\n",
    "\n",
    "for num, art in zip(nums, article_subs):\n",
    "    #print(num, \":\", art)\n",
    "    if True:#rule_num == int(re.findall(\"\\d+\", num)[0]):\n",
    "        sentences = re.sub(\"\\n\", \" \\n \", art)\n",
    "        sentences = unidecode.unidecode(sentences)\n",
    "        sentences = re.sub(website_pattern, '', sentences)\n",
    "        sentences = re.sub(\" \\n \", \"\", sentences)\n",
    "        sentences = re.sub(footer_pattern, ' ', sentences)\n",
    "        citations = re.findall(citation_pattern, sentences) \n",
    "        rules = re.split(citation_pattern, sentences)\n",
    "        print(citations)\n",
    "        rule_index = 0\n",
    "        for citation_index, citation in enumerate(citations):\n",
    "            citation_type = \"single\"\n",
    "            suffix = None\n",
    "            if len(rules[citation_index]) > 3:\n",
    "                rule = rules[citation_index]\n",
    "                #citation_str.append({\"rule_num\": rule_num,\"text\":rules[citation_index][-1]})\n",
    "                #suffix check\n",
    "                if len(rules) > citation_index + 1:\n",
    "                    #print(re.findall(suffix_pattern, rules[citation_index+1]))\n",
    "                    #print(rules[citation_index+1])\n",
    "                    #print(rules[citation_index+1].lstrip(\"[ \\.,:;()]*\").startswith(suffix_pattern_list))\n",
    "                    pass\n",
    "                rule_index = citation_index\n",
    "            else:\n",
    "                # multicitation or in sentence citation\n",
    "                if len(rules[citation_index]) == 0 and citation_index == 0: # in sentence citation, just direct to the next sentence\n",
    "                    rule_index += 1\n",
    "                    rule = rules[rule_index]\n",
    "                    citation_type = \"in_sentence\"\n",
    "                else:\n",
    "                    citation_type = \"multi\"\n",
    "                    #result_dic[-1]['citation_type'] = citation_type\n",
    "                    #if len(rules[citation_index+1]) >  0:\n",
    "                    #    citation_str.append({\"rule_num\": rule_num,\"text\":rules[citation_index+1][:max(1, len(rules[citation_index+1]))]})\n",
    "                    #if len(rules) - 1 > citation_index and re.findall(\"[where]|[which]|[in which].*\",rules[citation_index+1]):\n",
    "                    #    suffix = rules[citation_index+1]\n",
    "                    rule = rules[rule_index] # multi citation, just keep the old sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_pattern = r'http[s]?:\\/\\/hudoc.echr.coe.int\\/[a-z]+\\?i\\=\\d+\\-\\d+'\n",
    "website_pattern = r'([^ :]*):\\/\\/(?:([^:]*):([^@]*)@|)([^/:]{1,}):?(\\d*)?(\\/[^? ]*)\\??((?:[^=&# ]*=?[^&# ]*&?)*)#?([^ ]*)?'\n",
    "footer_pattern = r\"Guide on Article \\d+ of the Convention \\- [A-Za-z ]+ European Court of Human Rights \\d+\\/\\d+ Last update: \\d+.\\d+.\\d+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"The case of Ribcheva and Others v. Bulgaria concerned the death of a law-enforcement officer during a planned operation. The Court considered that,  \\nCentre for Legal Resources on behalf of Valentin Campeanu v. Romania [GC], 2014, SSSS 131 and 143-144,\\nMalik Babayev v. Azerbaijan [GC] (no. 12) )) )) ) or contractual military service (Boychenko v. Russia, 2021). Powell v. the United Kingdom (II) (dec.)) and that an issue may arise under Article 2 where it is shown that the authorities of a Contracting State have put an individual \\n Marius Alexandru and Marinela Stefan v. Romania (dec.), SSSS 103-104 and  12-43 and SS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_pattern = \"[A-Z]+[A-Za-z.\\- ]*v\\.[A-Za-z.\\- ]+[GCIdecmeritsrevision\\[\\]().\\d\\- ]*[,S ]*[\\-\\d ]*[and]{0,3}[\\-\\d ]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(citation_pattern, sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_article_header = {}\n",
    "p = re.compile('[A-Z]+\\.  [a-zA-Z0-9 ]+')\n",
    "for m in p.finditer(first_article):\n",
    "    first_article_header = { 'article_header': m.group(), 'start': m.start()}\n",
    "    break\n",
    "#sections+=splitted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_article_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_article_header_text = first_article[len(first_article_header['article_header']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_article_header_text = first_article_header_text.replace(\"\\n\", \"\")\n",
    "first_article_header_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_citation = '\\([A-Za-z. ]+, § \\d+\\)'\n",
    "s2_citation = \"\\([A-Za-z. ]+ [[A-Z]*], § \\d+\\)\"\n",
    "s3_citation = \"\\([A-Za-z. ]+ \\([A-Za-z]+\\.\\)\\)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = re.findall(s1_citation + \"|\" + s2_citation, first_article_header_text)\n",
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = re.split(s1_citation + \"|\" + s2_citation, first_article_header_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [rule for rule in texts if len(rule) > 5]\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for citation, rule in zip(citations, rules):\n",
    "    data.append({\"article_header\": first_article_header['article_header'], \"sentence\": rule, \"citation\": citation})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('[A-Z]+\\.  [a-zA-Z0-9 ]+')\n",
    "for m in p.finditer(second_article):\n",
    "    second_article_header = m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_article_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_article_text = second_article[len(second_article_header):]\n",
    "second_article_text = second_article_text.replace(\"\\n\", \"\")\n",
    "second_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = re.findall(s1_citation + \"|\" + s2_citation + \"|\" + s3_citation, second_article_text)\n",
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = re.split(s1_citation + \"|\" + s2_citation + \"|\" + s3_citation, second_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [rule for rule in texts if len(rule) > 5]\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for citation, rule in zip(citations, rules):\n",
    "    data.append({\"article_header\": second_article_header, \"sentence\": rule, \"citation\": citation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_article_subs = re.split(\"\\n\\n\\d+\\.  \", third_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('[A-Z]+\\.  [a-zA-Z0-9 ]+')\n",
    "for m in p.finditer(third_article):\n",
    "    third_article_header = m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_article_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_article_text = third_article[len(third_article_header):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(third_article_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in third_article_subs:\n",
    "    if sub == third_article_header:\n",
    "        third_article_subs.remove(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(third_article_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sub in enumerate(third_article_subs):\n",
    "    third_article_subs[index] = sub.replace(\"\\n\", \"\")\n",
    "third_article_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'http:\\/\\/hudoc.echr.coe.int\\/[a-z]+\\?i\\=\\d+\\-\\d+'\n",
    "footer = r\"Guide on Article \\d+ of the Convention \\- [A-Za-z ]+ European Court of Human Rights \\d+\\/\\d+ Last update: \\d+.\\d+.\\d+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sub in enumerate(third_article_subs):\n",
    "    #print(index)\n",
    "    #print(sub)\n",
    "    third_article_subs[index] = re.sub(pattern, '', third_article_subs[index])\n",
    "    third_article_subs[index] = re.sub(footer, '', third_article_subs[index])\n",
    "    third_article_subs[index] = unidecode.unidecode(third_article_subs[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_article_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_citation = '[A-Za-z. ]+, SS \\d+'\n",
    "s2_citation = \"[A-Za-z. ]+ [[A-Z]*], SS \\d+\"\n",
    "s3_citation = \"[A-Za-z. ]+ \\([A-Za-z]+\\.\\)\"\n",
    "s4_citation = \"[ ]*[A-Za-z. ]+[[A-Z]*]*, [S]+ [\\d+]+[\\-]*[\\d+]*[;]*\"\n",
    "generic = s1_citation + \"|\" + s2_citation + \"|\" + s3_citation\n",
    "multi_citation_pattern = \"[A-Za-z. ]*[\\[GC\\]]*[\\(dec.\\)]*, S{2,4} \\d+\\-*\\d*;?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name = \"[A-Za-z. ]\"\n",
    "gc = \"\\[GC\\]\"\n",
    "dec = \"\\(dec\\)\"\n",
    "par_sign = \"S\"\n",
    "par_num = \"\\d+\\-*\\d*;*\"\n",
    "citation_pattern = \"[A-Za-z. ]*[\\[GC\\]]*[\\(dec.\\)]*,*[ \\d]*, S{2,4} \\d+\\-*\\d*;?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = [re.findall(citation_pattern, sub) for sub in third_article_subs]\n",
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [re.split(citation_pattern, sub) for sub in third_article_subs]\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = []\n",
    "rule_num = 0\n",
    "for corrected_rules, rule_citation in zip(rules, citations):\n",
    "    corrected_rules = corrected_rules[:-1]\n",
    "    for rule, citation in zip(corrected_rules, rule_citation):\n",
    "        if len(rule) > 0:\n",
    "            result_dic.append({\"rule_num\": rule_num, \"sentence\": rule, \"citation\": citation})\n",
    "        else:\n",
    "            result_dic.append({\"rule_num\": rule_num, \"sentence\": result_dic[-1]['sentence'], 'citation': citation})\n",
    "    rule_num += 1\n",
    "\n",
    "result_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for result in result_dic:\n",
    "    data.append({\"article_header\": third_article_header, \"rule_num\": result['rule_num'], \"sentence\": result['sentence'], \"citation\": result['citation']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"citation_oriented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a15aa2fc1c99caeb472113b030ebaf85da516cf305c41df06fa77ae20ed9b549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
