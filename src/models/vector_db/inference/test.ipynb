{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/upadro/code/thesis\n",
      "/home/upadro/code/thesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/upadro/anaconda3/envs/rohit_work/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "path = current_path.split(\"thesis\")[0] + \"thesis\"\n",
    "print(path)\n",
    "os.chdir(path)\n",
    "print(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vector_db.commons.input_loader import InputLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_input_from_dir(input_data_path):\n",
    "        files = []\n",
    "        for (dirpath, dirnames, filenames) in os.walk(input_data_path):\n",
    "            for filename in filenames:\n",
    "                if \"json\" in filename:\n",
    "                    files.append(os.path.join(dirpath, filename))\n",
    "        input_loader = InputLoader()\n",
    "        total_inference_datapoints = []\n",
    "        for file in files:\n",
    "            individual_datapoints = input_loader.load_data(data_file=file)\n",
    "            total_inference_datapoints.extend(individual_datapoints) # type: ignore\n",
    "        return total_inference_datapoints\n",
    "\n",
    "# data = load_all_input_from_dir(\"src/models/single_datapoints/common\")\n",
    "data = load_all_input_from_dir(\"input/inference_input/english/unique_query_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['query', 'case_name', 'relevant_paragrpahs', 'paragraph_numbers', 'link', 'all_paragraphs', 'id'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/upadro/anaconda3/envs/rohit_work/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer, and move the model to GPU if available\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)  # Move model to GPU\n",
    "\n",
    "# Function to encode a list of paragraphs or queries using BERT\n",
    "def encode_texts(texts):\n",
    "    # Tokenize and encode, move inputs to the correct device\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to GPU if available\n",
    "    \n",
    "    # Get embeddings from BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # Take the mean of the last hidden state for each input text and move to CPU\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Ensure the output is on CPU\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    relevance = [1 if x in actual else 0 for x in predicted]\n",
    "    r = np.asarray(relevance)[:k]\n",
    "    return np.sum(r) / len(actual) if len(actual) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "metadata = []\n",
    "\n",
    "# Set to track already encoded links\n",
    "encoded_links = set()\n",
    "\n",
    "# Iterate over each data point to encode all paragraphs\n",
    "for i, datapoint in enumerate(data):\n",
    "    case_name = datapoint['case_name']\n",
    "    link = datapoint['link']\n",
    "    \n",
    "    # Check if the link has already been encoded\n",
    "    if link in encoded_links:\n",
    "        # print(f\"Link {link} already encoded. Skipping...\")\n",
    "        continue  # Skip this data point as it's already encoded\n",
    "    \n",
    "    # Combine all paragraphs into one per paragraph set\n",
    "    paragraphs = [\"\\n\".join(paras) for paras in datapoint['all_paragraphs']]\n",
    "    \n",
    "    # Encode all paragraphs for the current data point\n",
    "    paragraph_embeddings = encode_texts(paragraphs)  # Ensure this returns CPU embeddings\n",
    "    \n",
    "    # Add each paragraph's embedding to the FAISS index and keep metadata\n",
    "    for j, embedding in enumerate(paragraph_embeddings):\n",
    "        all_embeddings.append(embedding)  # Append the numpy array (CPU-based)\n",
    "        metadata.append({\n",
    "            \"case_name\": case_name,\n",
    "            \"link\": link,\n",
    "            \"paragraph_index\": j,\n",
    "            \"paragraph_text\": paragraphs[j]\n",
    "        })\n",
    "    \n",
    "    # Mark this link as encoded\n",
    "    encoded_links.add(link)\n",
    "    # print(f\"Encoded and added paragraphs for link: {link}\")\n",
    "\n",
    "# Convert embeddings list to numpy array\n",
    "all_embeddings_np = np.array(all_embeddings).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings added to FAISS index: 88078\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = all_embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(all_embeddings_np)\n",
    "print(f\"Total embeddings added to FAISS index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall at 2%: 0.0794\n",
      "Mean Recall at 5%: 0.0943\n",
      "Mean Recall at 10%: 0.1044\n"
     ]
    }
   ],
   "source": [
    "recalls_2_percent = []\n",
    "recalls_5_percent = []\n",
    "recalls_10_percent = []\n",
    "\n",
    "# Iterate over each data point to rank paragraphs based on the given query\n",
    "for i, datapoint in enumerate(data):\n",
    "    case_name = datapoint['case_name']\n",
    "    link = datapoint['link']\n",
    "    \n",
    "    # Get the paragraph numbers from the dataset (1-indexed)\n",
    "    actual_paragraph_numbers = datapoint.get('paragraph_numbers', [])\n",
    "    \n",
    "    # Use the provided queries in the data point and concatenate them into a single query\n",
    "    queries = datapoint.get('query', [])\n",
    "    \n",
    "    # If there are no queries, skip this data point\n",
    "    if not queries:\n",
    "        print(f\"No queries found for case: {case_name}\")\n",
    "        continue\n",
    "\n",
    "    # Combine all queries into a single query string separated by commas\n",
    "    combined_query = \", \".join(queries)\n",
    "\n",
    "    # Encode the combined query as a single query\n",
    "    query_embedding = encode_texts([combined_query])[0]  # Single embedding for the combined query\n",
    "    \n",
    "    # Search the FAISS index for this query\n",
    "    query_embedding = query_embedding.reshape(1, -1).astype('float32')  # Reshape for FAISS\n",
    "    distances, indices = index.search(query_embedding, len(all_embeddings))  # Get all paragraphs ranked\n",
    "    \n",
    "    # Filter results for this data point\n",
    "    filtered_results = [\n",
    "        (metadata[idx], distance) for idx, distance in zip(indices[0], distances[0])\n",
    "        if metadata[idx][\"case_name\"] == case_name and metadata[idx][\"link\"] == link\n",
    "    ]\n",
    "    \n",
    "    # Get the top percentages for each filtered result\n",
    "    top_2_percent = max(1, int(len(filtered_results) * 0.02))  # Top 2% of filtered results\n",
    "    top_5_percent = max(1, int(len(filtered_results) * 0.05))  # Top 5% of filtered results\n",
    "    top_10_percent = max(1, int(len(filtered_results) * 0.1))  # Top 10% of filtered results\n",
    "    \n",
    "    # Get the paragraph numbers for top percentages\n",
    "    top_2_percent_paragraphs = [(result_metadata[\"paragraph_index\"] + 1) for result_metadata, _ in filtered_results[:top_2_percent]]\n",
    "    top_5_percent_paragraphs = [(result_metadata[\"paragraph_index\"] + 1) for result_metadata, _ in filtered_results[:top_5_percent]]\n",
    "    top_10_percent_paragraphs = [(result_metadata[\"paragraph_index\"] + 1) for result_metadata, _ in filtered_results[:top_10_percent]]\n",
    "    \n",
    "    # Calculate individual recalls for each percentage\n",
    "    recall_2 = recall_at_k(actual_paragraph_numbers, top_2_percent_paragraphs, k=len(actual_paragraph_numbers))\n",
    "    recall_5 = recall_at_k(actual_paragraph_numbers, top_5_percent_paragraphs, k=len(actual_paragraph_numbers))\n",
    "    recall_10 = recall_at_k(actual_paragraph_numbers, top_10_percent_paragraphs, k=len(actual_paragraph_numbers))\n",
    "    \n",
    "    # Store the individual recall values\n",
    "    recalls_2_percent.append(recall_2)\n",
    "    recalls_5_percent.append(recall_5)\n",
    "    recalls_10_percent.append(recall_10)\n",
    "\n",
    "# Calculate the mean recall for each percentage\n",
    "mean_recall_2_percent = np.mean(recalls_2_percent)\n",
    "mean_recall_5_percent = np.mean(recalls_5_percent)\n",
    "mean_recall_10_percent = np.mean(recalls_10_percent)\n",
    "\n",
    "# Print the overall recall scores\n",
    "print(f\"Mean Recall at 2%: {mean_recall_2_percent:.4f}\")\n",
    "print(f\"Mean Recall at 5%: {mean_recall_5_percent:.4f}\")\n",
    "print(f\"Mean Recall at 10%: {mean_recall_10_percent:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rohit_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
